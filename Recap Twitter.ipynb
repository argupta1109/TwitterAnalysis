{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fabd27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (1.6.6)\n",
      "Requirement already satisfied: six>=1.10 in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (1.26.16)\n",
      "Requirement already satisfied: bleach in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adityarajgupta/anaconda3/lib/python3.11/site-packages (from requests->kaggle) (3.4)\n"
     ]
    }
   ],
   "source": [
    "#For Installing Kaggle\n",
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f39d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload your Kaggle.json File\n",
    "#Configuring the path of kaggle.json file\n",
    "#This is fix Code ti import yout API \n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3c851f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading sentiment140.zip to /Users/adityarajgupta/Downloads/MANIT Bhopal/4 Coding/Recap Analysis\n",
      "100%|██████████████████████████████████████| 80.9M/80.9M [00:11<00:00, 6.66MB/s]\n",
      "100%|██████████████████████████████████████| 80.9M/80.9M [00:11<00:00, 7.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "#API to fetech the dataset from kaggle\n",
    "#Importing twitter sentiment dataset\n",
    "!kaggle datasets download -d kazanova/sentiment140\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "741ca6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the Compessed Dataset\n",
    "from zipfile import ZipFile\n",
    "#importing the zipline from ZipFile\n",
    "dataset = 'sentiment140.zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "361b61c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SucessFul\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(dataset,'r') as zip:\n",
    "    # r for Read, using as zip for extract\n",
    "    zip.extractall()\n",
    "    print (\"SucessFul\")\n",
    "    \n",
    "#Rename the dataset file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d24d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing the dependencies\n",
    "import numpy as np\n",
    "import pandas as pd #Data into Structure\n",
    "import re #Regular Expression\n",
    "from nltk.corpus import stopwords #Natural Language Tool Kit\n",
    "from nltk.stem.porter import PorterStemmer #Stemming is used to change the words in root words like Chaning Walks ,Walking to Walk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Change the words into Numerical Data for Processing of data\n",
    "from sklearn.model_selection import train_test_split #For Spliting the data into Train and Test\n",
    "from sklearn.linear_model import LogisticRegression #Basic Ml used in this\n",
    "from sklearn.metrics import accuracy_score #Accuracy and Performance of the System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80edc9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adityarajgupta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#This are the Words doesn't change(Or add) the Meaning to the Sentence\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f5a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Processing\n",
    "#Loading the data from csv file to pandas Dataframe\n",
    "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6391edc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the Number of Rows and Columns\n",
    "twitter_data.shape\n",
    "twitter_data.head() #Printing thr First five Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312481a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naming the columns and reading the dataset again\n",
    "column_names = ['target','id','data','flag','user','text']\n",
    "twitter_data = pd.read_csv('training.1600000.processed.noemoticon.csv',names=column_names, encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "086beffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          data      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head() #Printing thr First five Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87a7d983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "id        0\n",
       "data      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the number of missing value in the dataset \n",
    "twitter_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b823600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the distribution of target Columns\n",
    "twitter_data['target'].value_counts()\n",
    "#This is done to check the equal distribution of the Positive and Negative Tweets\n",
    "#If it is not even divided we have to upsampling and Downsampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "281ea6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "1    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the target from 4 to 1 this done for making it simple and easy and to Look good\n",
    "twitter_data.replace({'target':{4:1}},inplace=True)\n",
    "#Checking the distribution of target Columns\n",
    "twitter_data['target'].value_counts()\n",
    "#0 --> Negative \n",
    "#1 --> Positive \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bd3549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming :- Stemming is the Process of reducing a word to its Root Words Like Actor, Actress, Acting = Act\n",
    "port_stem = PorterStemmer()\n",
    "def stemming(content):\n",
    "    #Content is the import for the function\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    # Removing all the Charter from the tweet except the A-Z and a-z\n",
    "    #It remove all the Number, Punchtation, Arrow, Comma, Special char and @, etc\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    #Changing the words to lower as it donesn't the meaning from upper to lower\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Split thw words and adding into the List\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    #Changing the Word to root word\n",
    "    #Operation of change the Word into stemmed words which are not Present in the Stopwords\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    #Again joining the Words from List to tweet\n",
    "    \n",
    "    return stemmed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3be4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twitter_data['stemmed_content'] = twitter_data['text'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5c065bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot http twitpic com zl awww bummer sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dive mani time ball manag save rest g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          data      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \\\n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...   \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...   \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire    \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                     stemmed_content  \n",
       "0  switchfoot http twitpic com zl awww bummer sho...  \n",
       "1  upset updat facebook text might cri result sch...  \n",
       "2  kenichan dive mani time ball manag save rest g...  \n",
       "3                    whole bodi feel itchi like fire  \n",
       "4                      nationwideclass behav mad see  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46bed30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          switchfoot http twitpic com zl awww bummer sho...\n",
      "1          upset updat facebook text might cri result sch...\n",
      "2          kenichan dive mani time ball manag save rest g...\n",
      "3                            whole bodi feel itchi like fire\n",
      "4                              nationwideclass behav mad see\n",
      "                                 ...                        \n",
      "1599995                           woke school best feel ever\n",
      "1599996    thewdb com cool hear old walt interview http b...\n",
      "1599997                         readi mojo makeov ask detail\n",
      "1599998    happi th birthday boo alll time tupac amaru sh...\n",
      "1599999    happi charitytuesday thenspcc sparkschar speak...\n",
      "Name: stemmed_content, Length: 1600000, dtype: object\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "1599995    1\n",
      "1599996    1\n",
      "1599997    1\n",
      "1599998    1\n",
      "1599999    1\n",
      "Name: target, Length: 1600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(twitter_data['stemmed_content'])\n",
    "print(twitter_data['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4652806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steparting the data and label\n",
    "X = twitter_data['stemmed_content'].values\n",
    "#Storing thr value of text into x\n",
    "Y = twitter_data['target'].values\n",
    "#Storing thr value of target into Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c93018c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['switchfoot http twitpic com zl awww bummer shoulda got david carr third day'\n",
      " 'upset updat facebook text might cri result school today also blah'\n",
      " 'kenichan dive mani time ball manag save rest go bound' ...\n",
      " 'readi mojo makeov ask detail'\n",
      " 'happi th birthday boo alll time tupac amaru shakur'\n",
      " 'happi charitytuesday thenspcc sparkschar speakinguph h']\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c64a197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e77c8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data to Training data and Test Data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, stratify=Y,random_state=2)\n",
    "#test_size = 0.2 means that 20% of the data is test data\n",
    "#stratify Mean equal distribution of Positive tweet and Negative Tweet\n",
    "#Random_State will insure that all the people have the same Set of test and Train Because it is always Random selected for Test and Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59dd93ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000,) (1280000,) (320000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b785c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['watch saw iv drink lil wine' 'hatermagazin'\n",
      " 'even though favourit drink think vodka coke wipe mind time think im gonna find new drink'\n",
      " ... 'eager monday afternoon'\n",
      " 'hope everyon mother great day wait hear guy store tomorrow'\n",
      " 'love wake folger bad voic deeper']\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "150bc06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d64ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the textual data to Numerical Data\n",
    "#In convert all the text into Numerical\n",
    "vectorizer = TfidfVectorizer()\n",
    "#Depending upon the Number of repeat of the words in tweet. \n",
    "#Depend upon that word on that what effecting it is making on Positive or Negative Tweet\n",
    "#All the words are converted into some important Values\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "#For train we use the fit_transform to transform data in Numerical\n",
    "X_test = vectorizer.transform(X_test)\n",
    "#Based upon the training data we transform the test data into numerical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1861768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 443066)\t0.4484755317023172\n",
      "  (0, 235045)\t0.41996827700291095\n",
      "  (0, 109306)\t0.3753708587402299\n",
      "  (0, 185193)\t0.5277679060576009\n",
      "  (0, 354543)\t0.3588091611460021\n",
      "  (0, 436713)\t0.27259876264838384\n",
      "  (1, 160636)\t1.0\n",
      "  (2, 288470)\t0.16786949597862733\n",
      "  (2, 132311)\t0.2028971570399794\n",
      "  (2, 150715)\t0.18803850583207948\n",
      "  (2, 178061)\t0.1619010109445149\n",
      "  (2, 409143)\t0.15169282335109835\n",
      "  (2, 266729)\t0.24123230668976975\n",
      "  (2, 443430)\t0.3348599670252845\n",
      "  (2, 77929)\t0.31284080750346344\n",
      "  (2, 433560)\t0.3296595898028565\n",
      "  (2, 406399)\t0.32105459490875526\n",
      "  (2, 129411)\t0.29074192727957143\n",
      "  (2, 407301)\t0.18709338684973031\n",
      "  (2, 124484)\t0.1892155960801415\n",
      "  (2, 109306)\t0.4591176413728317\n",
      "  (3, 172421)\t0.37464146922154384\n",
      "  (3, 411528)\t0.27089772444087873\n",
      "  (3, 388626)\t0.3940776331458846\n",
      "  (3, 56476)\t0.5200465453608686\n",
      "  :\t:\n",
      "  (1279996, 390130)\t0.22064742191076112\n",
      "  (1279996, 434014)\t0.2718945052332447\n",
      "  (1279996, 318303)\t0.21254698865277746\n",
      "  (1279996, 237899)\t0.2236567560099234\n",
      "  (1279996, 291078)\t0.17981734369155505\n",
      "  (1279996, 412553)\t0.18967045002348676\n",
      "  (1279997, 112591)\t0.7574829183045267\n",
      "  (1279997, 273084)\t0.4353549002982409\n",
      "  (1279997, 5685)\t0.48650358607431304\n",
      "  (1279998, 385313)\t0.4103285865588191\n",
      "  (1279998, 275288)\t0.38703346602729577\n",
      "  (1279998, 162047)\t0.34691726958159064\n",
      "  (1279998, 156297)\t0.3137096161546449\n",
      "  (1279998, 153281)\t0.28378968751027456\n",
      "  (1279998, 435463)\t0.2851807874350361\n",
      "  (1279998, 124765)\t0.32241752985927996\n",
      "  (1279998, 169461)\t0.2659980990397061\n",
      "  (1279998, 93795)\t0.21717768937055476\n",
      "  (1279998, 412553)\t0.2816582375021589\n",
      "  (1279999, 96224)\t0.5416162421321443\n",
      "  (1279999, 135384)\t0.6130934129868719\n",
      "  (1279999, 433612)\t0.3607341026233411\n",
      "  (1279999, 435572)\t0.31691096877786484\n",
      "  (1279999, 31410)\t0.248792678366695\n",
      "  (1279999, 242268)\t0.19572649660865402\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "842f379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d7116db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the ML Model\n",
    "#Logistic Regression is used as we have just two value input and result alongwith it, input is present in Numerical form\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# Max Itersation is max number of time it can go it is upto 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0033a7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train)\n",
    "#It will train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55e04bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the training data :  0.81020859375\n"
     ]
    }
   ],
   "source": [
    "#Model Evalution\n",
    "#Accuracy Score\n",
    "\n",
    "#Accuracy score on the training data\n",
    "#It is True value on which the Model is train\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train,X_train_prediction)\n",
    "print(\"Accuracy score on the training data : \",training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9168be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on the test data :  0.77801875\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score on the test data\n",
    "#It is new Value to the Model is tested\n",
    "X_test_prediction = model.predict(X_test )\n",
    "test_data_accuracy = accuracy_score(Y_test,X_test_prediction)\n",
    "print(\"Accuracy score on the test data : \",test_data_accuracy)\n",
    "#The accuracy of training data and Test Data Must be equal otherwise it is assumed that the Model is Overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d08c5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To save the Model to use it later, As we have not to train the Model again and again for the best result.\n",
    "import pickle\n",
    "filename = 'trained_model.sav' #Name to the file as be different but for this case is trained_model.sav\n",
    "pickle.dump(model,open(filename,'wb'))\n",
    "# model is the name of the model we created in the time of Logistic Regression\n",
    "#wb is write the file in Binary format\n",
    "#dump is used to create the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa00d433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the saved Model for future prediction\n",
    "#Loading the saved Model\n",
    "loaded_model = pickle.load(open('trained_model.sav','rb'))\n",
    "#rb mean that reading the file in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca4254c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#Testing our model for save model\n",
    "X_new = X_test[200]\n",
    "print(Y_test[200])\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83c528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
